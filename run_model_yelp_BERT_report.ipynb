{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer)\n",
    "\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (convert_examples_to_features,\n",
    "                        output_modes, processors)\n",
    "from utils_seedly import processors as seedly_processor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration for training\n",
    "Configuration for such as: director for data, log and outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'model_type':  'bert',\n",
    "    'model_name': 'bert-base-cased',\n",
    "    'task_name': 'binary',\n",
    "    'output_dir': 'outputs_yelp_logged_BERT_report/',\n",
    "    'cache_dir': 'cache/',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'fp16': False,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'max_seq_length': 128,\n",
    "    'output_mode': 'classification',\n",
    "    'train_batch_size': 64,\n",
    "    'eval_batch_size': 64,\n",
    "\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 1,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 4e-5,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_ratio': 0.06,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "\n",
    "    'logging_steps': 500,\n",
    "    'evaluate_during_training': False,\n",
    "    'save_steps': 2000,\n",
    "    'eval_all_checkpoints': True,\n",
    "\n",
    "    'overwrite_output_dir': False,\n",
    "    'reprocess_input_data': False,\n",
    "    'notes': 'Using Yelp Reviews dataset'\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n",
    "#     raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class = (BertConfig, BertForSequenceClassification, BertTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer for BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/chungsoo002/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 5,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/chungsoo002/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(args['model_name'], num_labels=5, finetuning_task=args['task_name'])\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained BERT model\n",
    "Also specify the specific details of the architecture: such as number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# model = model_class.from_pretrained(args['model_name'], num_labels=5, hidden_dropout_prob=0.3)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "Here we define functions to efficiently load data and then feed into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "\n",
    "if task in processors.keys() and task in output_modes.keys():\n",
    "    processor = processors[task]()\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels = len(label_list)\n",
    "else:\n",
    "    raise KeyError(f'{task} not found in processors or in output_modes. Please check utils.py.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class yelpDataset(Dataset):\n",
    "  def __init__(self, examples, label_list, args, tokenizer, output_mode):\n",
    "    self.examples=examples\n",
    "    self.label_list = label_list\n",
    "    self.args = args\n",
    "    self.tokenizer = tokenizer\n",
    "    self.output_mode = output_mode\n",
    "      \n",
    "  def __len__(self):\n",
    "    # return size of dataset\n",
    "    return len(self.examples)\n",
    "      \n",
    "  def __getitem__(self, idx):\n",
    "    features = convert_examples_to_features(self.examples[idx], self.label_list, self.args['max_seq_length'], self.tokenizer, self.output_mode,\n",
    "                cls_token_at_end=bool(self.args['model_type'] in ['xlnet']),            \n",
    "                cls_token=self.tokenizer.cls_token,\n",
    "                cls_token_segment_id=2 if self.args['model_type'] in ['xlnet'] else 0,\n",
    "                sep_token=self.tokenizer.sep_token,\n",
    "                sep_token_extra=bool(self.args['model_type'] in ['roberta']),           \n",
    "                pad_on_left=bool(self.args['model_type'] in ['xlnet']),                 \n",
    "                pad_token=self.tokenizer.convert_tokens_to_ids([self.tokenizer.pad_token])[0],\n",
    "                pad_token_segment_id=4 if self.args['model_type'] in ['xlnet'] else 0)\n",
    "    \n",
    "    all_input_ids = torch.tensor(features.input_ids, dtype=torch.long)\n",
    "    all_input_mask = torch.tensor(features.input_mask, dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor(features.segment_ids, dtype=torch.long)\n",
    "    if self.output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor(features.label_id, dtype=torch.long)\n",
    "    elif self.output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor(features.label_id, dtype=torch.float)\n",
    "\n",
    "    dataset = (all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, mode):\n",
    "    processor = processors[task]()\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    \n",
    "    label_list = processor.get_labels()\n",
    "    if mode == 'train':\n",
    "        examples = processor.get_train_examples(args['data_dir'])\n",
    "    elif mode == 'eval':\n",
    "        examples = processor.get_dev_examples(args['data_dir'])\n",
    "    elif mode == 'test':\n",
    "        examples = processor.get_test_examples(args['data_dir'])\n",
    "    \n",
    "        \n",
    "    if __name__ == \"__main__\":\n",
    "        dataset=yelpDataset(examples, label_list, args, tokenizer, output_mode)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to compute evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    cf = confusion_matrix(labels, preds, labels=[0,1,2,3,4])\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"cf\": cf\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Eval, Test function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# def train(dataset, model, tokenizer):\n",
    "#     EVAL_TASK = args['task_name']\n",
    "#     tb_writer = SummaryWriter('./log_yelp_train_BERT_report')\n",
    "#     train_dataset, eval_dataset, test_dataset = dataset\n",
    "    \n",
    "#     train_sampler = RandomSampler(train_dataset)\n",
    "#     train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "#     eval_sampler = SequentialSampler(eval_dataset)\n",
    "#     eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "#     test_sampler = SequentialSampler(test_dataset)\n",
    "#     test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
    "    \n",
    "#     t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "#     no_decay = ['bias', 'LayerNorm.weight']\n",
    "#     optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "#         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "#         ]\n",
    "    \n",
    "#     warmup_steps = math.ceil(t_total * args['warmup_ratio'])\n",
    "#     args['warmup_steps'] = warmup_steps if args['warmup_steps'] == 0 else args['warmup_steps']\n",
    "    \n",
    "#     optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "#     scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n",
    "    \n",
    "#     if args['fp16']:\n",
    "#         try:\n",
    "#             from apex import amp\n",
    "#         except ImportError:\n",
    "#             raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "#         model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "#     logger.info(\"***** Running training *****\")\n",
    "#     logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "#     logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "#     logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "#     logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "#     logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "#     global_step = 0\n",
    "    \n",
    "#     model.zero_grad()\n",
    "#     train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "#     epoch = 0\n",
    "#     for _ in train_iterator:\n",
    "#         epoch += 1\n",
    "#         epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n",
    "#         tr_loss, logging_loss = 0.0, 0.0\n",
    "#         tr_acc, log_acc = 0.0, 0.0\n",
    "#         nb_train_steps = 0\n",
    "#         for step, batch in enumerate(epoch_iterator):\n",
    "#             model.train()\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             inputs = {'input_ids':      batch[0],\n",
    "#                       'attention_mask': batch[1],\n",
    "#                       'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "#                       'labels':         batch[3]}\n",
    "#             outputs = model(**inputs)\n",
    "#             loss, logits = outputs[0:2]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "#             print(\"\\r%f\" % loss, end='')\n",
    "#             nb_train_steps += 1\n",
    "#             preds = logits.detach().cpu().numpy()\n",
    "#             out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "\n",
    "#             if args['output_mode'] == \"classification\":\n",
    "#                 preds = np.argmax(preds, axis=1)\n",
    "#             elif args['output_mode'] == \"regression\":\n",
    "#                 preds = np.squeeze(preds)\n",
    "#             result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "#             c = result['cf']\n",
    "#             acc=(c[0,0] + c[1,1] + c[2,2] + c[3,3] + c[4,4])/np.sum(np.sum(c))\n",
    "\n",
    "\n",
    "#             if args['gradient_accumulation_steps'] > 1:\n",
    "#                 loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "#             if args['fp16']:\n",
    "#                 with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "#                     scaled_loss.backward()\n",
    "#                 torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "\n",
    "#             else:\n",
    "#                 loss.backward()\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "#             tr_loss += loss.item()\n",
    "#             tr_acc = (tr_acc * (nb_train_steps-1) + acc)/(nb_train_steps) \n",
    "#             if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "#                 optimizer.step()\n",
    "#                 scheduler.step()  # Update learning rate schedule\n",
    "#                 model.zero_grad()\n",
    "#                 global_step += 1\n",
    "\n",
    "#                 if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
    "#                     # Log metrics\n",
    "#                     tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "#                     tb_writer.add_scalar('train_loss', (tr_loss - logging_loss)/args['logging_steps'], global_step)\n",
    "#                     logging_loss = tr_loss\n",
    "#                     tb_writer.add_scalar('train_acc', tr_acc, global_step)\n",
    "                    \n",
    "#                     # Eval!\n",
    "#                     prefix = global_step\n",
    "#                     logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "#                     logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "#                     logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "#                     eval_loss = 0.0\n",
    "#                     nb_eval_steps = 0\n",
    "#                     preds = None\n",
    "#                     out_label_ids = None\n",
    "#                     eval_gen=tqdm_notebook(eval_dataloader, desc=\"Evaluating\")\n",
    "#                     for (eval_step,batch) in enumerate(eval_gen):      \n",
    "#                         if eval_step%100==0:\n",
    "#                             model.eval()\n",
    "#                             batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "#                             with torch.no_grad():\n",
    "#                                 inputs = {'input_ids':      batch[0],\n",
    "#                                           'attention_mask': batch[1],\n",
    "#                                           'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "#                                           'labels':         batch[3]}\n",
    "#                                 outputs = model(**inputs)\n",
    "#                                 tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "#                                 eval_loss += tmp_eval_loss.mean().item()\n",
    "#                             nb_eval_steps += 1\n",
    "#                             if preds is None:\n",
    "#                                 preds = logits.detach().cpu().numpy()\n",
    "#                                 out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "#                             else:\n",
    "#                                 preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "#                                 out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "#                     eval_loss = eval_loss / nb_eval_steps\n",
    "#                     if args['output_mode'] == \"classification\":\n",
    "#                         preds = np.argmax(preds, axis=1)\n",
    "#                     elif args['output_mode'] == \"regression\":\n",
    "#                         preds = np.squeeze(preds)\n",
    "#                     result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "#                     c = result['cf']\n",
    "#                     eval_acc=(c[0,0] + c[1,1] + c[2,2] + c[3,3] + c[4,4])/np.sum(np.sum(c))\n",
    "#                     tb_writer.add_scalar('eval_loss', eval_loss, global_step)\n",
    "#                     tb_writer.add_scalar('eval_acc', eval_acc, global_step)\n",
    "                    \n",
    "#                     # Test!\n",
    "#                     logger.info(\"***** Running test {} *****\".format(prefix))\n",
    "#                     logger.info(\"  Num examples = %d\", len(test_dataset))\n",
    "#                     logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "#                     test_loss = 0.0\n",
    "#                     nb_test_steps = 0\n",
    "#                     preds = None\n",
    "#                     out_label_ids = None\n",
    "#                     test_gen = tqdm_notebook(test_dataloader, desc=\"Testing\")\n",
    "#                     for (test_step,batch) in enumerate(test_gen):\n",
    "#                         if test_step%100==0:\n",
    "#                             model.eval()\n",
    "#                             batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "#                             with torch.no_grad():\n",
    "#                                 inputs = {'input_ids':      batch[0],\n",
    "#                                           'attention_mask': batch[1],\n",
    "#                                           'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "#                                           'labels':         batch[3]}\n",
    "#                                 outputs = model(**inputs)\n",
    "#                                 tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "#                                 test_loss += tmp_eval_loss.mean().item()\n",
    "#                             nb_test_steps += 1\n",
    "#                             if preds is None:\n",
    "#                                 preds = logits.detach().cpu().numpy()\n",
    "#                                 out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "#                             else:\n",
    "#                                 preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "#                                 out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "#                     test_loss = test_loss / nb_test_steps\n",
    "#                     if args['output_mode'] == \"classification\":\n",
    "#                         preds = np.argmax(preds, axis=1)\n",
    "#                     elif args['output_mode'] == \"regression\":\n",
    "#                         preds = np.squeeze(preds)\n",
    "#                     result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "#                     c = result['cf']\n",
    "#                     test_acc=(c[0,0] + c[1,1] + c[2,2] + c[3,3] + c[4,4])/np.sum(np.sum(c))\n",
    "#                     tb_writer.add_scalar('test_loss', test_loss, global_step)\n",
    "#                     tb_writer.add_scalar('test_acc', test_acc, global_step)\n",
    "                    \n",
    "\n",
    "#                 if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
    "#                     # Save model checkpoint\n",
    "#                     output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n",
    "#                     if not os.path.exists(output_dir):\n",
    "#                         os.makedirs(output_dir)\n",
    "#                     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#                     model_to_save.save_pretrained(output_dir)\n",
    "#                     logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     return global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# if args['do_train']:\n",
    "#     train_dataset = load_and_cache_examples(task, tokenizer, 'train')\n",
    "#     eval_dataset = load_and_cache_examples(task, tokenizer, 'eval')\n",
    "#     test_dataset = load_and_cache_examples(task, tokenizer, 'test')\n",
    "#     dataset = [train_dataset, eval_dataset, test_dataset]\n",
    "#     global_step= train(dataset, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# if args['do_train']:\n",
    "#     if not os.path.exists(args['output_dir']):\n",
    "#             os.makedirs(args['output_dir'])\n",
    "#     logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "#     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#     model_to_save.save_pretrained(args['output_dir'])\n",
    "#     tokenizer.save_pretrained(args['output_dir'])\n",
    "#     torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples_seedly(task, tokenizer, mode):\n",
    "    processor = seedly_processor[task]()\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    \n",
    "    label_list = processor.get_labels()\n",
    "    if mode == 'train':\n",
    "        examples = processor.get_train_examples('data_seedly/')\n",
    "    elif mode == 'eval':\n",
    "        examples = processor.get_dev_examples('data_seedly/')\n",
    "    elif mode == 'test':\n",
    "        examples = processor.get_test_examples('data_seedly/')\n",
    "    \n",
    "        \n",
    "    if __name__ == \"__main__\":\n",
    "        dataset=yelpDataset(examples, label_list, args, tokenizer, output_mode)\n",
    "    return dataset\n",
    "\n",
    "def evaluate_yelp(model, tokenizer, prefix=\"\"):\n",
    "    EVAL_TASK = args['task_name']\n",
    "    test_dataset = load_and_cache_examples(task, tokenizer, 'test')\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm_notebook(test_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            _, logits = outputs[:2]\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    confusion_matrix = result['cf']\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"12345\"],\n",
    "                      columns = [i for i in \"12345\"])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True, cmap='gist_earth_r')\n",
    "    acc=(confusion_matrix[0,0] + confusion_matrix[1,1] + confusion_matrix[2,2] + confusion_matrix[3,3] + confusion_matrix[4,4])/np.sum(np.sum(confusion_matrix))\n",
    "    print(\"\\nTest Accuracy of BERT model trained on yelp dataset tested on yelp: {:.4f}\".format(acc))\n",
    "    \n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print('\\nTotal parameters:', total_param)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(args['output_dir'])\n",
    "model.to(device);\n",
    "evaluate_yelp(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on seedly\n",
    "After training on YELP we train on seedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transfer(train_dataset, model, tokenizer):\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "    \n",
    "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    \n",
    "    warmup_steps = math.ceil(t_total * args['warmup_ratio'])\n",
    "    args['warmup_steps'] = warmup_steps if args['warmup_steps'] == 0 else args['warmup_steps']\n",
    "    \n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n",
    "    \n",
    "    if args['fp16']:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    \n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "    epoch = 0\n",
    "    for _ in train_iterator:\n",
    "        epoch += 1\n",
    "        epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n",
    "        tr_loss, logging_loss = 0.0, 0.0\n",
    "        nb_train_steps = 0\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            print(\"\\r%f\" % loss, end='')\n",
    "            nb_train_steps += 1\n",
    "\n",
    "\n",
    "            if args['gradient_accumulation_steps'] > 1:\n",
    "                loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "            if args['fp16']:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "\n",
    "                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "        \n",
    "\n",
    "    return global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seedly(model, tokenizer, prefix=\"\"):\n",
    "    EVAL_TASK = args['task_name']\n",
    "       \n",
    "    \n",
    "    test_dataset = load_and_cache_examples_seedly(task, tokenizer, 'test')\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm_notebook(test_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            _, logits = outputs[:2]\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    confusion_matrix = result['cf']\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index = [i for i in \"12345\"],\n",
    "                      columns = [i for i in \"12345\"])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True, cmap='gist_earth_r')\n",
    "    acc=(confusion_matrix[0,0] + confusion_matrix[1,1] + confusion_matrix[2,2] + confusion_matrix[3,3] + confusion_matrix[4,4])/np.sum(np.sum(confusion_matrix))\n",
    "    print(\"\\nTest Accuracy of BERT model trained on yelp dataset tested on seedly: {:.4f}\".format(acc))\n",
    "    \n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print('\\nTotal parameters:', total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file outputs_yelp_logged_BERT_report/config.json\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.3,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 5,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file outputs_yelp_logged_BERT_report/pytorch_model.bin\n",
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Num examples = 4382\n",
      "INFO:__main__:  Num Epochs = 20\n",
      "INFO:__main__:  Total train batch size  = 64\n",
      "INFO:__main__:  Gradient Accumulation steps = 1\n",
      "INFO:__main__:  Total optimization steps = 1380\n",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7549ec383274931ae5f8e00c4fee2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [01:19<25:17, 79.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46fddbfe49e415eb5fd1c6ddeb58e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [02:40<23:59, 80.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d348372f734c7b958f7107a1e6852d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [03:58<22:33, 79.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45020cbdce1c401e86ebf3e7731a1506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [05:18<21:15, 79.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8405f796e0244c8bafbcee34e34f34af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [06:38<19:53, 79.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89613008e2d48f29f682f1a877d8633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.319021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [07:57<18:32, 79.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c352c3aed66f4f38b661d1ee89427868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [09:17<17:15, 79.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f66050ae7e4170b781b045015d4488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [10:37<15:59, 79.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c08d3cc4c140d284c8aee30a769215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.083696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [11:59<14:46, 80.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3156f333373b44acb20dfd58e2896785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.086230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [13:19<13:22, 80.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507901ff45542b2a82aa797dfc2147c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [14:41<12:06, 80.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c20f780568450cb605b16aeffbab1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [16:01<10:45, 80.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5b7cb3486a4a08a470655388a5e84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [17:21<09:22, 80.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6a93b9703f40249379cbda53fc5875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.124706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [18:43<08:04, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ed0a75b20d4cbba0510dd2cce2cde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 15/20 [20:04<06:43, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a6c142ec3f4fbf82f6453a7bf02ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 16/20 [21:23<05:21, 80.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e998ced326427ab1434502b3f344b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|████████▌ | 17/20 [22:44<04:01, 80.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24af391479f74300aa38a85fc7ed8497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 18/20 [24:05<02:41, 80.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d33340e23de4dd096a1a1fdcd12efd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████▌| 19/20 [25:26<01:20, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9079209a48c48f7b34fce5877039c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=69, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.129605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [26:47<00:00, 80.37s/it]\n",
      "INFO:__main__:Saving model checkpoint to outputs_seedly_logged_BERT_report_transfer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Uncomment this if you want to train for the first time\n",
    "# model = model_class.from_pretrained(args['output_dir'])\n",
    "# model.to(device);\n",
    "# # start seedly training,,,returns model\n",
    "# args['output_dir']='outputs_seedly_logged_BERT_report_transfer'\n",
    "# args['num_train_epochs'] = 20\n",
    "\n",
    "# if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n",
    "#     raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))\n",
    "\n",
    "# if args['do_train']:\n",
    "#     train_dataset = load_and_cache_examples_seedly(task, tokenizer, 'train')\n",
    "#     global_step= train_transfer(train_dataset, model, tokenizer)\n",
    "#     if not os.path.exists(args['output_dir']):\n",
    "#             os.makedirs(args['output_dir'])\n",
    "#     logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "#     model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#     model_to_save.save_pretrained(args['output_dir'])\n",
    "#     tokenizer.save_pretrained(args['output_dir'])\n",
    "#     torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file outputs_seedly_logged_BERT_report_transfer/config.json\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.3,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 5,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file outputs_seedly_logged_BERT_report_transfer/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ea74445b9d4d43a8c2c322bf67a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test Accuracy of BERT model trained on yelp dataset tested on seedly: 0.7117\n",
      "\n",
      "Total parameters: 108314117\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "args['output_dir']='outputs_seedly_logged_BERT_report_transfer'\n",
    "model = model_class.from_pretrained(args['output_dir'])\n",
    "model.to(device);\n",
    "evaluate_seedly(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
